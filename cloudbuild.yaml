steps:
# Clone repository with Git LFS optimization for models
- name: 'gcr.io/cloud-builders/git'
  id: 'clone-models'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      mkdir -p /workspace/models
      echo "Cloning repository with Git LFS optimization..."
      GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/spaces/ALSv/video-face-swap.git /workspace/huggingface
      cd /workspace/huggingface
      echo "Selectively pulling only required model files..."
      git lfs pull --include="models/inswapper_128.onnx"
      git lfs pull --include="models/detection_Resnet50_Final.pth"
      mkdir -p /workspace/models
      cp -r /workspace/huggingface/models/* /workspace/models/ 2>/dev/null || true
      echo "Models directory contents:"
      ls -la /workspace/models
  timeout: '600s'

# Build the container image with multi-stage optimization
- name: 'gcr.io/cloud-builders/docker'
  id: 'build-image'
  waitFor: ['clone-models']
  args:
    - 'build'
    - '-t'
    - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA}'
    - '--build-arg'
    - 'BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')'
    - '--build-arg'
    - 'VCS_REF=${SHORT_SHA}'
    - '--build-arg'
    - 'VERSION=${SHORT_SHA}'
    - '--cache-from'
    - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:latest'
    - '.'
  timeout: '1200s'  # Reduced timeout as model downloads are handled separately

# Capture image size for logging and monitoring
- name: 'gcr.io/cloud-builders/docker'
  id: 'image-size'
  waitFor: ['build-image']
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      echo "Checking optimized image size:"
      docker images ${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA} --format "{{.Size}}"
      IMAGE_SIZE=$(docker images ${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA} --format "{{.Size}}")
      echo "Image size: $IMAGE_SIZE"
      
      # Log this metric to Cloud Monitoring
      echo "{\"name\": \"custom.googleapis.com/container/image_size\", \"value\": \"$IMAGE_SIZE\", \"labels\": {\"sha\": \"${SHORT_SHA}\"}}" > /workspace/image_size.json

# Run container security scan 
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'security-scan'
  waitFor: ['build-image']
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      gcloud artifacts docker images scan ${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA} \
        --format='json(response.scan)' > /workspace/scan_results.json
      echo "Vulnerabilities found:"
      cat /workspace/scan_results.json | jq -r '.response.scan.findings[] | select(.finding.severity=="CRITICAL") | .finding.vulnerability + " - " + .finding.severity' || true
      
      # Check for critical vulnerabilities and decide whether to proceed
      CRITICAL_COUNT=$(cat /workspace/scan_results.json | jq -r '.response.scan.findings[] | select(.finding.severity=="CRITICAL") | .finding.vulnerability' | wc -l || echo "0")
      if [ "$CRITICAL_COUNT" -gt "5" ]; then
        echo "Too many critical vulnerabilities found: $CRITICAL_COUNT. Build failed."
        exit 1
      fi

# Run basic unit/integration tests
- name: '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA}'
  id: 'test-image'
  waitFor: ['build-image']
  entrypoint: 'bash'
  args: 
    - '-c'
    - |
      pip install pytest pytest-cov pytest-mock requests-mock pytest-env pytest-timeout
      chmod +x ./scripts/run_tests.sh
      ./scripts/run_tests.sh --unit --integration --ci
  timeout: '300s'

# Push the container image to Artifact Registry
- name: 'gcr.io/cloud-builders/docker'
  id: 'push-image'
  waitFor: ['test-image', 'security-scan']
  args: ['push', '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA}']

# Create a tag for latest
- name: 'gcr.io/cloud-builders/docker'
  id: 'tag-latest'
  waitFor: ['push-image']
  args: ['tag', '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA}', '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:latest']

# Push the latest tag
- name: 'gcr.io/cloud-builders/docker'
  id: 'push-latest'
  waitFor: ['tag-latest']
  args: ['push', '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:latest']

# Set up lifecycle policy for repository cleanup
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'setup-lifecycle-policy'
  waitFor: ['push-latest']
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # Set up a lifecycle policy to keep only the latest 5 images and delete older ones
      cat > /workspace/lifecycle-policy.json << EOF
      {
        "rules": [
          {
            "action": {"type": "DELETE"},
            "condition": {
              "tagState": "TAGGED",
              "tagPrefixes": [""],
              "newerThan": {"days": 30},
              "olderThan": {"days": 60}
            },
            "selection": {
              "tagPrefixes": [""],
              "orderBy": {"field": "CREATE_TIME", "direction": "DESC"},
              "offsetIndex": 5
            }
          },
          {
            "action": {"type": "DELETE"},
            "condition": {
              "tagState": "UNTAGGED",
              "olderThan": {"days": 7}
            }
          }
        ]
      }
      EOF
      
      # Apply the lifecycle policy
      gcloud artifacts repositories set-cleanup-policies video-face-swap \
        --project=${PROJECT_ID} \
        --location=${_REGION} \
        --policy-file=/workspace/lifecycle-policy.json

# Set up Terraform
- name: 'hashicorp/terraform:1.5.7'
  id: 'terraform-init'
  waitFor: ['push-latest']
  entrypoint: 'sh'
  args:
    - '-c'
    - |
      cd terraform
      terraform init
  env:
    - 'TF_VAR_project_id=${PROJECT_ID}'
    - 'TF_VAR_region=${_REGION}'

# Terraform plan
- name: 'hashicorp/terraform:1.5.7'
  id: 'terraform-plan'
  waitFor: ['terraform-init']
  entrypoint: 'sh'
  args:
    - '-c'
    - |
      cd terraform
      terraform plan -var "project_id=${PROJECT_ID}" -var "region=${_REGION}" -var "container_image_url=${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA}" -out=tfplan
  env:
    - 'TF_VAR_project_id=${PROJECT_ID}'
    - 'TF_VAR_region=${_REGION}'

# Terraform apply
- name: 'hashicorp/terraform:1.5.7'
  id: 'terraform-apply'
  waitFor: ['terraform-plan']
  entrypoint: 'sh'
  args:
    - '-c'
    - |
      cd terraform
      terraform apply -auto-approve tfplan
  env:
    - 'TF_VAR_project_id=${PROJECT_ID}'
    - 'TF_VAR_region=${_REGION}'

# Add Cloud Run revision tags and annotations
- name: 'gcr.io/cloud-builders/gcloud'
  id: 'annotate-revision'
  waitFor: ['terraform-apply']
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # Get the latest revision name
      REVISION=$(gcloud run services describe video-face-swap-api --region=${_REGION} --format="value(status.latestCreatedRevisionName)")
      
      # Add annotations to capture build info
      gcloud run revisions update $REVISION \
        --region=${_REGION} \
        --update-annotations=build_id=${BUILD_ID},commit_sha=${SHORT_SHA},build_timestamp=$(date -u +'%Y-%m-%dT%H:%M:%SZ')

# Run synthetic test against the deployed service
- name: 'curlimages/curl:latest'
  id: 'test-deployment'
  waitFor: ['annotate-revision']
  entrypoint: 'sh'
  args:
    - '-c'
    - |
      # Get the service URL
      SERVICE_URL=$(gcloud run services describe video-face-swap-api --region=${_REGION} --format="value(status.url)")
      
      # Test health endpoint
      curl -f "$${SERVICE_URL}/health" || exit 1
      
      echo "Deployment verified successfully"

substitutions:
  _REGION: us-central1  # Default region, can be overridden

images:
- '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:${SHORT_SHA}'
- '${_REGION}-docker.pkg.dev/${PROJECT_ID}/video-face-swap/api:latest'

artifacts:
  objects:
    location: 'gs://${PROJECT_ID}-vfs-temp/build-artifacts/${BUILD_ID}/'
    paths: ['workspace/scan_results.json', 'terraform/tfplan', 'workspace/lifecycle-policy.json', 'workspace/image_size.json']

options:
  machineType: 'E2_HIGHCPU_8'  # Use a higher-performance machine for faster builds
  logging: CLOUD_LOGGING_ONLY
  dynamicSubstitutions: true

timeout: '2700s'  # 45 minutes
